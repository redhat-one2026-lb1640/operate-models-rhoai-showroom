= Introduction

This module is expected to 10 minutes to complete.


== Story

<img src="images/story-cover.png" alt="The Loremaster and the Shadow Algorithm" title="The Loremaster and the Shadow Algorithm" />

== Motivation


AI will change how we live, work, and experience our everyday lives. 
In this hands-on lab, participants get a last of the tools that will power this future. 
We will use Openshift AI, Red Hats AIML platform based on OpenShift Container Platform to create models and deploy these to production quality.

In an era where adversaries are increasingly using AI to evade detection, security teams must leverage advanced platforms to deploy, manage, and secure their own AI capabilities at speed and scale.
 This session demonstrates how Red Hat OpenShift AI empowers teams to rapidly transition from experimental models in a Jupyter Workbench to production-grade deploymentsâ€”while embedding security throughout the lifecycle.
 
 We will walk through a complete AI Threat Hunting use case
 * starting with data exploration and model development inside OpenShift AI Workbench
 * moving to model packaging and deployment as an API service, and finally applying Zero Trust principles to protect both the model and its data.
 * Attendees will see how to integrate role-based access controls (RBAC), network isolation, and model observability for compliance and operational safety. 
 
 
 Key takeaways include: 
 
 * How to use OpenShift AI Workbench for rapid iteration on security-focused models.
 * Best practices for securing AI endpoints and pipelines against adversarial attacks.
 * Applying OpenShift-native monitoring and governance to sustain trust in AI-powered threat hunting. 
 * Whether you are a data scientist, security engineer, or platform architect, you will leave with a clear blueprint for securely operationalizing AI models in mission-critical environments.


== Introduction

== What does Operationalize mean?



=== Production hardening

production hardening of AI systems for operations means we need to prepare our architecture, infrastructure, and processes to ensure that AI models can be deployed, monitored, and maintained effectively in a production environment. This involves several key aspects:
* Scalability: Ensuring that the AI systems can handle increased workloads and user demands without performance degradation.
* Reliability: Implementing robust systems that can operate continuously with minimal downtime and can recover quickly from failures.
* Security: Protecting AI models and data from unauthorized access, tampering, and adverse attacks.



=== Testing 

...

=== Deploy


=== Update


=== Scale 


=== Retire






Using the "buildah from" command will download and meld the container image. This particular image we are using is the Red Hat Universal Base Image or UBI. From the ourput of the command, you will notice that we are pulling down the latest one, which is for RHEL 9. 

. Execute the  download the Standard UBI
image from Red Hat's registry.

+
[source,sh,role=execute]
----
buildah from registry.access.redhat.com/ubi9/ubi
----

[#repositories]
== Installing Repositories
In this lab, you are going to containerize a software package that is already
packaged in RPM format and stored in the Extra Packages for Enterprise Linux
(EPEL) repository.

Software often has requirements for prerequisite software that must be installed
on the machine for it to work properly.  `yum` will resolve those
dependencies for you, as long as it can locate the required packages in
repositories defined on the machine.  The Red Hat Universal Base Image (UBI)
downloaded in the previous step has access to some Red Hat Enterprise Linux
repositories.  However, the target package for the lab is from EPEL.  

. In the command below, `buildah` is going to run a command on the
`ubi-working-container` image.  The `--` indicates that the command should be
executed from within the container, which means the results will be applied into
the container image.  Lastly, you are providing the `yum` command to install a
package that defines all of the repositories from EPEL, `epel-release-latest-9`.

+
[source,bash]
----
buildah run ubi-working-container -- yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm
----


. You can verify that the above command did not install the RPM on the host system.

+
[source,bash]
----
rpm -q epel-release
----

NOTE: If your repository configurations are not distributed as an RPM, but instead as
individual `.repo` files, you could use the `buildah copy` command to copy
files from the host operating system into the container image.  You will see
an example of using `buildah copy` later in this lab.

[#software]
== Installing Software


. Now that the yum repositories are defined within the container, execute 
another `yum install`, within the container, to install the target
software: `moon-buggy`.

+
[source,bash]
----
buildah run ubi-working-container -- yum -y install moon-buggy
----


== Committing the Container Image

. At this point, the container is configured.  It is time to transition from a
working container into a committed image.  In the command below, you will use
the `buildah` command to commit the working container to an image called:
`moon-buggy`.

+
[source,bash]
----
buildah commit ubi-working-container moon-buggy
----

+
. The output of `podman image list` should confirm the image was created.

+
[source,bash]
----
podman image list
----


== Deploy the Container

Now the software has been installed and a new container image created.  It is
time to spawn a runtime of the container image and validate the software.  The
software we are using is a command line command.  

. When you `run` the container,
it will be in interactive (`-it`) mode, based on the `moon-buggy` container
image and the command run interactively will be `/usr/bin/moon-buggy`.

+
[source,bash]
----
podman run -it moon-buggy /usr/bin/moon-buggy
----

+
[source,textinfo]
----

<<< OUTPUT ABRIDGED >>>
               MM     MM   OOOOO    OOOOO   NN     N
               M M   M M  O     O  O     O  N N    N
               M  M M  M  O     O  O     O  N  N   N
               M   M   M  O     O  O     O  N   N  N
               M       M  O     O  O     O  N    N N
               M       M   OOOOO    OOOOO   N     NN

                     BBBBBB   U     U   GGGGG    GGGGG   Y     Y
                     B     B  U     U  G     G  G     G   Y   Y
                     BBBBBB   U     U  G        G          Y Y
                     B     B  U     U  G   GGG  G   GGG     Y
                     B     B  U     U  G     G  G     G    Y
                     BBBBBB    UUUUU    GGGGG    GGGGG   YY

<<< OUTPUT ABRIDGED >>>
----

. You can now play the Moon Buggy game, which is a text-based version of the
popular Moon Patrol.  When you are finished, use the `q` command to quit the
game, which will terminate the container.

+
Alternatively, you can use `podman` to kill the running container from
*Terminal 2*.

+
[source,bash]
----
podman kill $(podman ps | grep -v CONTAINER | cut -f1 -d" " )
----
